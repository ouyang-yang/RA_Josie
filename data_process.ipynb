{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SIN = pd.read_csv(\"data_CNCF_SIN.csv\")\n",
    "df_TWN = pd.read_csv(\"data_CNCF_TWN.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = [110, 120, 130, 140, 150, 160, 170, 180, 190]\n",
    "immediate_x_values = [1, 2, 4, 8]\n",
    "delayed_x_values = [5, 6, 8, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the transformed data\n",
    "transformed_data = {}\n",
    "\n",
    "# Iterate over each row to transform the data as specified\n",
    "for index, row in df_TWN.iterrows():\n",
    "    participant_id = row['Participant']\n",
    "    a = row['a']\n",
    "    b = row['b']\n",
    "    c = row['c']  # Value of 'a + b' which is also equal to 'c' as given\n",
    "    d = row['d']\n",
    "    \n",
    "    # Determine the timeframe type and construct column names based on conditions\n",
    "    if b == 0 and a in [1, 2, 4, 8]:\n",
    "        # Immediate timeframe\n",
    "        for y in y_values:\n",
    "            col_name = f\"immediate_week{c}_{y}\"\n",
    "            # Check the value of 'd' against the tens digit of 'y'\n",
    "            if d < ((y-100) // 10):\n",
    "                value = \"now\"\n",
    "            else:\n",
    "                value = \"future\"\n",
    "            \n",
    "            # Add or update the entry in the transformed_data dictionary\n",
    "            transformed_data.setdefault(participant_id, {})[col_name] = value\n",
    "    \n",
    "    elif b == 4 and a in [1, 2, 4, 8]:\n",
    "        # Delayed timeframe\n",
    "        for y in y_values:\n",
    "            col_name = f\"delayed_week{c}_{y}\"\n",
    "            # Check the value of 'd' against the tens digit of 'y'\n",
    "            if d < ((y-100) // 10):\n",
    "                value = \"now\"\n",
    "            else:\n",
    "                value = \"future\"\n",
    "            \n",
    "            # Add or update the entry in the transformed_data dictionary\n",
    "            transformed_data.setdefault(participant_id, {})[col_name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transformed data dictionary into a DataFrame\n",
    "transformed_SIN = pd.DataFrame.from_dict(transformed_data, orient='index').reset_index()\n",
    "transformed_SIN.rename(columns={'index': 'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 欄位順序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ordered columns\n",
    "ordered_columns = ['ID']  # Start with 'ID' column\n",
    "# Add immediate and delayed columns in the specified order\n",
    "for timeframe in [\"immediate\", \"delayed\"]:\n",
    "    x_values = immediate_x_values if timeframe == \"immediate\" else delayed_x_values\n",
    "    for x in x_values:\n",
    "        for y in y_values:\n",
    "            ordered_columns.append(f\"{timeframe}_week{x}_{y}\")\n",
    "\n",
    "# Reindex the DataFrame with the ordered columns (filling missing columns with NaN if necessary)\n",
    "transformed_SIN = transformed_SIN.reindex(columns=ordered_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 問卷欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_SIN = transformed_SIN.merge(\n",
    "    df_SIN[['participant', 'treatment', 'gender', 'race', 'econ', 'course', 'immi', 'identity', 'r1', 'l1', 'pro1', 'pro2', 'often1', 'often2']],\n",
    "    left_on='ID', right_on='participant', how='left'\n",
    ")\n",
    "\n",
    "# Set the values for each column based on the merged columns\n",
    "transformed_SIN['treatment'] = transformed_SIN['treatment'].apply(lambda x: \"will\" if x == \"CF\" else \"no will\")\n",
    "transformed_SIN['race'] = transformed_SIN['race'].str.rstrip(';')\n",
    "transformed_SIN['major'] = transformed_SIN['econ'].apply(lambda x: \"Econ\" if x == \"Yes\" else \"Business\")\n",
    "transformed_SIN['year'] = transformed_SIN['course']\n",
    "transformed_SIN['immigration_status'] = transformed_SIN['immi']\n",
    "transformed_SIN['identity'] = transformed_SIN.apply(lambda row: row['r1'] if row['identity'] == \"Others\" else row['identity'], axis=1)\n",
    "transformed_SIN['language'] = transformed_SIN['l1']\n",
    "transformed_SIN['pro_in_English'] = transformed_SIN['pro1']\n",
    "transformed_SIN['pro_in_Mandarin'] = transformed_SIN['pro2']\n",
    "transformed_SIN['often_use_English'] = transformed_SIN['often1']\n",
    "transformed_SIN['often_use_Mandarin'] = transformed_SIN['often2']\n",
    "\n",
    "# Drop the redundant columns used for merging\n",
    "transformed_SIN = transformed_SIN.drop(columns=['participant', 'econ', 'course', 'immi', 'r1', 'l1', 'pro1', 'pro2', 'often1', 'often2'])\n",
    "transformed_SIN = transformed_SIN.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 155 entries, 0 to 1232\n",
      "Data columns (total 85 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   155 non-null    int64  \n",
      " 1   immediate_week1_110  155 non-null    object \n",
      " 2   immediate_week1_120  155 non-null    object \n",
      " 3   immediate_week1_130  155 non-null    object \n",
      " 4   immediate_week1_140  155 non-null    object \n",
      " 5   immediate_week1_150  155 non-null    object \n",
      " 6   immediate_week1_160  155 non-null    object \n",
      " 7   immediate_week1_170  155 non-null    object \n",
      " 8   immediate_week1_180  155 non-null    object \n",
      " 9   immediate_week1_190  155 non-null    object \n",
      " 10  immediate_week2_110  155 non-null    object \n",
      " 11  immediate_week2_120  155 non-null    object \n",
      " 12  immediate_week2_130  155 non-null    object \n",
      " 13  immediate_week2_140  155 non-null    object \n",
      " 14  immediate_week2_150  155 non-null    object \n",
      " 15  immediate_week2_160  155 non-null    object \n",
      " 16  immediate_week2_170  155 non-null    object \n",
      " 17  immediate_week2_180  155 non-null    object \n",
      " 18  immediate_week2_190  155 non-null    object \n",
      " 19  immediate_week4_110  155 non-null    object \n",
      " 20  immediate_week4_120  155 non-null    object \n",
      " 21  immediate_week4_130  155 non-null    object \n",
      " 22  immediate_week4_140  155 non-null    object \n",
      " 23  immediate_week4_150  155 non-null    object \n",
      " 24  immediate_week4_160  155 non-null    object \n",
      " 25  immediate_week4_170  155 non-null    object \n",
      " 26  immediate_week4_180  155 non-null    object \n",
      " 27  immediate_week4_190  155 non-null    object \n",
      " 28  immediate_week8_110  155 non-null    object \n",
      " 29  immediate_week8_120  155 non-null    object \n",
      " 30  immediate_week8_130  155 non-null    object \n",
      " 31  immediate_week8_140  155 non-null    object \n",
      " 32  immediate_week8_150  155 non-null    object \n",
      " 33  immediate_week8_160  155 non-null    object \n",
      " 34  immediate_week8_170  155 non-null    object \n",
      " 35  immediate_week8_180  155 non-null    object \n",
      " 36  immediate_week8_190  155 non-null    object \n",
      " 37  delayed_week5_110    155 non-null    object \n",
      " 38  delayed_week5_120    155 non-null    object \n",
      " 39  delayed_week5_130    155 non-null    object \n",
      " 40  delayed_week5_140    155 non-null    object \n",
      " 41  delayed_week5_150    155 non-null    object \n",
      " 42  delayed_week5_160    155 non-null    object \n",
      " 43  delayed_week5_170    155 non-null    object \n",
      " 44  delayed_week5_180    155 non-null    object \n",
      " 45  delayed_week5_190    155 non-null    object \n",
      " 46  delayed_week6_110    155 non-null    object \n",
      " 47  delayed_week6_120    155 non-null    object \n",
      " 48  delayed_week6_130    155 non-null    object \n",
      " 49  delayed_week6_140    155 non-null    object \n",
      " 50  delayed_week6_150    155 non-null    object \n",
      " 51  delayed_week6_160    155 non-null    object \n",
      " 52  delayed_week6_170    155 non-null    object \n",
      " 53  delayed_week6_180    155 non-null    object \n",
      " 54  delayed_week6_190    155 non-null    object \n",
      " 55  delayed_week8_110    155 non-null    object \n",
      " 56  delayed_week8_120    155 non-null    object \n",
      " 57  delayed_week8_130    155 non-null    object \n",
      " 58  delayed_week8_140    155 non-null    object \n",
      " 59  delayed_week8_150    155 non-null    object \n",
      " 60  delayed_week8_160    155 non-null    object \n",
      " 61  delayed_week8_170    155 non-null    object \n",
      " 62  delayed_week8_180    155 non-null    object \n",
      " 63  delayed_week8_190    155 non-null    object \n",
      " 64  delayed_week12_110   155 non-null    object \n",
      " 65  delayed_week12_120   155 non-null    object \n",
      " 66  delayed_week12_130   155 non-null    object \n",
      " 67  delayed_week12_140   155 non-null    object \n",
      " 68  delayed_week12_150   155 non-null    object \n",
      " 69  delayed_week12_160   155 non-null    object \n",
      " 70  delayed_week12_170   155 non-null    object \n",
      " 71  delayed_week12_180   155 non-null    object \n",
      " 72  delayed_week12_190   155 non-null    object \n",
      " 73  treatment            155 non-null    object \n",
      " 74  gender               155 non-null    object \n",
      " 75  race                 155 non-null    object \n",
      " 76  identity             132 non-null    object \n",
      " 77  major                155 non-null    object \n",
      " 78  year                 155 non-null    int64  \n",
      " 79  immigration_status   132 non-null    object \n",
      " 80  language             132 non-null    object \n",
      " 81  pro_in_English       132 non-null    float64\n",
      " 82  pro_in_Mandarin      132 non-null    float64\n",
      " 83  often_use_English    132 non-null    float64\n",
      " 84  often_use_Mandarin   132 non-null    float64\n",
      "dtypes: float64(4), int64(2), object(79)\n",
      "memory usage: 104.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(transformed_SIN.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_SIN.to_excel(\"LSH_SIN.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the transformed data\n",
    "transformed_data = {}\n",
    "\n",
    "# Iterate over each row to transform the data as specified\n",
    "for index, row in df_TWN.iterrows():\n",
    "    participant_id = row['Participant']\n",
    "    a = row['a']\n",
    "    b = row['b']\n",
    "    c = row['c']  # Value of 'a + b' which is also equal to 'c' as given\n",
    "    d = row['d']\n",
    "    \n",
    "    # Determine the timeframe type and construct column names based on conditions\n",
    "    if b == 0 and a in [1, 2, 4, 8]:\n",
    "        # Immediate timeframe\n",
    "        for y in y_values:\n",
    "            col_name = f\"immediate_week{c}_{y}\"\n",
    "            # Check the value of 'd' against the tens digit of 'y'\n",
    "            if d < ((y-100) // 10):\n",
    "                value = \"now\"\n",
    "            else:\n",
    "                value = \"future\"\n",
    "            \n",
    "            # Add or update the entry in the transformed_data dictionary\n",
    "            transformed_data.setdefault(participant_id, {})[col_name] = value\n",
    "    \n",
    "    elif b == 4 and a in [1, 2, 4, 8]:\n",
    "        # Delayed timeframe\n",
    "        for y in y_values:\n",
    "            col_name = f\"delayed_week{c}_{y}\"\n",
    "            # Check the value of 'd' against the tens digit of 'y'\n",
    "            if d < ((y-100) // 10):\n",
    "                value = \"now\"\n",
    "            else:\n",
    "                value = \"future\"\n",
    "            \n",
    "            # Add or update the entry in the transformed_data dictionary\n",
    "            transformed_data.setdefault(participant_id, {})[col_name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transformed data dictionary into a DataFrame\n",
    "transformed_TWN = pd.DataFrame.from_dict(transformed_data, orient='index').reset_index()\n",
    "transformed_TWN.rename(columns={'index': 'ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ordered columns\n",
    "ordered_columns = ['ID']  # Start with 'ID' column\n",
    "# Add immediate and delayed columns in the specified order\n",
    "for timeframe in [\"immediate\", \"delayed\"]:\n",
    "    x_values = immediate_x_values if timeframe == \"immediate\" else delayed_x_values\n",
    "    for x in x_values:\n",
    "        for y in y_values:\n",
    "            ordered_columns.append(f\"{timeframe}_week{x}_{y}\")\n",
    "\n",
    "# Reindex the DataFrame with the ordered columns (filling missing columns with NaN if necessary)\n",
    "transformed_TWN = transformed_TWN.reindex(columns=ordered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_TWN = transformed_TWN.merge(\n",
    "    df_TWN[['Participant', 'Treatment', 'Gender', 'Taiwan', 'Econ', 'Course', 'laugnauge', 'otherLanguage', 'WhichLanguage', 'EngCountry', 'WhichCountry']],\n",
    "    left_on='ID', right_on='Participant', how='left'\n",
    ")\n",
    "\n",
    "# Set the values for each column based on the merged columns\n",
    "transformed_TWN['treatment'] = transformed_TWN['Treatment'].apply(lambda x: \"will\" if x == \"CF\" else \"no will\")\n",
    "transformed_TWN['gender'] = transformed_TWN['Gender']\n",
    "transformed_TWN['race'] = transformed_TWN['Taiwan']\n",
    "transformed_TWN['major'] = transformed_TWN['Econ'].apply(lambda x: \"Econ\" if x == \"是\" else \"Others\")\n",
    "transformed_TWN['year'] = transformed_TWN['Course']\n",
    "transformed_TWN['language'] = transformed_TWN.apply(lambda row: \"中文\" if row['otherLanguage'] == \"否\" else row['WhichLanguage'], axis=1)\n",
    "transformed_TWN['english_speaking_country'] = transformed_TWN.apply(lambda row: row['EngCountry'] if row['EngCountry'] == \"否\" else row['WhichCountry'], axis=1)\n",
    "\n",
    "# Drop the redundant columns used for merging\n",
    "transformed_TWN = transformed_TWN.drop(columns=['Participant', 'Treatment', 'Gender', 'Taiwan', 'Econ', 'Course', 'laugnauge', 'otherLanguage', 'WhichLanguage', 'EngCountry', 'WhichCountry'])\n",
    "transformed_TWN = transformed_TWN.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 155 entries, 0 to 1232\n",
      "Data columns (total 80 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   ID                        155 non-null    int64 \n",
      " 1   immediate_week1_110       155 non-null    object\n",
      " 2   immediate_week1_120       155 non-null    object\n",
      " 3   immediate_week1_130       155 non-null    object\n",
      " 4   immediate_week1_140       155 non-null    object\n",
      " 5   immediate_week1_150       155 non-null    object\n",
      " 6   immediate_week1_160       155 non-null    object\n",
      " 7   immediate_week1_170       155 non-null    object\n",
      " 8   immediate_week1_180       155 non-null    object\n",
      " 9   immediate_week1_190       155 non-null    object\n",
      " 10  immediate_week2_110       155 non-null    object\n",
      " 11  immediate_week2_120       155 non-null    object\n",
      " 12  immediate_week2_130       155 non-null    object\n",
      " 13  immediate_week2_140       155 non-null    object\n",
      " 14  immediate_week2_150       155 non-null    object\n",
      " 15  immediate_week2_160       155 non-null    object\n",
      " 16  immediate_week2_170       155 non-null    object\n",
      " 17  immediate_week2_180       155 non-null    object\n",
      " 18  immediate_week2_190       155 non-null    object\n",
      " 19  immediate_week4_110       155 non-null    object\n",
      " 20  immediate_week4_120       155 non-null    object\n",
      " 21  immediate_week4_130       155 non-null    object\n",
      " 22  immediate_week4_140       155 non-null    object\n",
      " 23  immediate_week4_150       155 non-null    object\n",
      " 24  immediate_week4_160       155 non-null    object\n",
      " 25  immediate_week4_170       155 non-null    object\n",
      " 26  immediate_week4_180       155 non-null    object\n",
      " 27  immediate_week4_190       155 non-null    object\n",
      " 28  immediate_week8_110       155 non-null    object\n",
      " 29  immediate_week8_120       155 non-null    object\n",
      " 30  immediate_week8_130       155 non-null    object\n",
      " 31  immediate_week8_140       155 non-null    object\n",
      " 32  immediate_week8_150       155 non-null    object\n",
      " 33  immediate_week8_160       155 non-null    object\n",
      " 34  immediate_week8_170       155 non-null    object\n",
      " 35  immediate_week8_180       155 non-null    object\n",
      " 36  immediate_week8_190       155 non-null    object\n",
      " 37  delayed_week5_110         155 non-null    object\n",
      " 38  delayed_week5_120         155 non-null    object\n",
      " 39  delayed_week5_130         155 non-null    object\n",
      " 40  delayed_week5_140         155 non-null    object\n",
      " 41  delayed_week5_150         155 non-null    object\n",
      " 42  delayed_week5_160         155 non-null    object\n",
      " 43  delayed_week5_170         155 non-null    object\n",
      " 44  delayed_week5_180         155 non-null    object\n",
      " 45  delayed_week5_190         155 non-null    object\n",
      " 46  delayed_week6_110         155 non-null    object\n",
      " 47  delayed_week6_120         155 non-null    object\n",
      " 48  delayed_week6_130         155 non-null    object\n",
      " 49  delayed_week6_140         155 non-null    object\n",
      " 50  delayed_week6_150         155 non-null    object\n",
      " 51  delayed_week6_160         155 non-null    object\n",
      " 52  delayed_week6_170         155 non-null    object\n",
      " 53  delayed_week6_180         155 non-null    object\n",
      " 54  delayed_week6_190         155 non-null    object\n",
      " 55  delayed_week8_110         155 non-null    object\n",
      " 56  delayed_week8_120         155 non-null    object\n",
      " 57  delayed_week8_130         155 non-null    object\n",
      " 58  delayed_week8_140         155 non-null    object\n",
      " 59  delayed_week8_150         155 non-null    object\n",
      " 60  delayed_week8_160         155 non-null    object\n",
      " 61  delayed_week8_170         155 non-null    object\n",
      " 62  delayed_week8_180         155 non-null    object\n",
      " 63  delayed_week8_190         155 non-null    object\n",
      " 64  delayed_week12_110        155 non-null    object\n",
      " 65  delayed_week12_120        155 non-null    object\n",
      " 66  delayed_week12_130        155 non-null    object\n",
      " 67  delayed_week12_140        155 non-null    object\n",
      " 68  delayed_week12_150        155 non-null    object\n",
      " 69  delayed_week12_160        155 non-null    object\n",
      " 70  delayed_week12_170        155 non-null    object\n",
      " 71  delayed_week12_180        155 non-null    object\n",
      " 72  delayed_week12_190        155 non-null    object\n",
      " 73  treatment                 155 non-null    object\n",
      " 74  gender                    155 non-null    object\n",
      " 75  race                      155 non-null    object\n",
      " 76  major                     155 non-null    object\n",
      " 77  year                      155 non-null    object\n",
      " 78  language                  153 non-null    object\n",
      " 79  english_speaking_country  155 non-null    object\n",
      "dtypes: int64(1), object(79)\n",
      "memory usage: 98.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(transformed_TWN.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_TWN.to_excel(\"LSH_TWN.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Location</th>\n",
       "      <th>SessionID</th>\n",
       "      <th>FutureTense</th>\n",
       "      <th>Mandarin</th>\n",
       "      <th>ID</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Period</th>\n",
       "      <th>a</th>\n",
       "      <th>...</th>\n",
       "      <th>Econmajor</th>\n",
       "      <th>laugnauge</th>\n",
       "      <th>otherLanguage</th>\n",
       "      <th>WhichLanguage</th>\n",
       "      <th>EngCountry</th>\n",
       "      <th>WhichCountry</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>AE</th>\n",
       "      <th>AF</th>\n",
       "      <th>chineseismainlanguage0english1ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>160517_1320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>中文</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>160517_1320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>中文</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>160517_1320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>中文</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>160517_1320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>中文</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>160517_1320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>中文</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>否</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Treatment  Location    SessionID  FutureTense  Mandarin  ID  \\\n",
       "0           0        CN         0  160517_1320            0         1   1   \n",
       "1           1        CN         0  160517_1320            0         1   1   \n",
       "2           2        CN         0  160517_1320            0         1   1   \n",
       "3           3        CN         0  160517_1320            0         1   1   \n",
       "4           4        CN         0  160517_1320            0         1   1   \n",
       "\n",
       "   Participant  Period  a  ...  Econmajor  laugnauge  otherLanguage  \\\n",
       "0            1       8  8  ...          1         中文              否   \n",
       "1            1       7  4  ...          1         中文              否   \n",
       "2            1       6  1  ...          1         中文              否   \n",
       "3            1       5  4  ...          1         中文              否   \n",
       "4            1       4  8  ...          1         中文              否   \n",
       "\n",
       "   WhichLanguage  EngCountry  WhichCountry  Purpose  AE  AF  \\\n",
       "0            NaN           否           NaN      NaN NaN NaN   \n",
       "1            NaN           否           NaN      NaN NaN NaN   \n",
       "2            NaN           否           NaN      NaN NaN NaN   \n",
       "3            NaN           否           NaN      NaN NaN NaN   \n",
       "4            NaN           否           NaN      NaN NaN NaN   \n",
       "\n",
       "  chineseismainlanguage0english1ma  \n",
       "0                              1.0  \n",
       "1                              1.0  \n",
       "2                              1.0  \n",
       "3                              1.0  \n",
       "4                              1.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TWN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
